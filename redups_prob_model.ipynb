{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from io import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvkulkarni/postdoc/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pmf(Counter):\n",
    "    \"\"\"A Counter with probabilities.\"\"\"\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Normalizes the PMF so the probabilities add to 1.\"\"\"\n",
    "        total = float(sum(self.values()))\n",
    "        for key in self:\n",
    "            self[key] /= total\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Adds two distributions.\n",
    "\n",
    "        The result is the distribution of sums of values from the\n",
    "        two distributions.\n",
    "\n",
    "        other: Pmf\n",
    "\n",
    "        returns: new Pmf\n",
    "        \"\"\"\n",
    "        pmf = Pmf()\n",
    "        for key1, prob1 in self.items():\n",
    "            for key2, prob2 in other.items():\n",
    "                pmf[key1 + key2] += prob1 * prob2\n",
    "        return pmf\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"Returns an integer hash value.\"\"\"\n",
    "        return id(self)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self is other\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Returns values and their probabilities, suitable for plotting.\"\"\"\n",
    "        return zip(*sorted(self.items()))\n",
    "    \n",
    "    def sample(self):\n",
    "        keys, vals= zip(*self.items())\n",
    "        return np.random.choice(keys, p=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_shm(p1, p2):\n",
    "    if (p2.find('schm')) == 0 or (p2.find('shm')==0):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_duplicate(p1, p2):\n",
    "    return p1==p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_change_consonant(p1, p2):\n",
    "    changes = list(difflib.ndiff(p1,p2))\n",
    "    vowel_set=set(['a','e','i','o','u'])\n",
    "    deleted_consonants=[]\n",
    "    added_consonants=[]\n",
    "    for c in changes:\n",
    "        if '-' in c and c.split(' ')[1] not in vowel_set:\n",
    "            deleted_consonants.append(c.split(' ')[1])\n",
    "        elif '+' in c and c.split(' ')[1]:\n",
    "            added_consonants.append(c.split(' ')[1])\n",
    "    if (len(added_consonants)==1) and len(deleted_consonants)==len(added_consonants):\n",
    "        if deleted_consonants[0]==added_consonants[0]:\n",
    "            print p1, p2\n",
    "        return True, deleted_consonants[0], added_consonants[0]\n",
    "    else:\n",
    "        return False,None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_change_vowel(p1, p2):\n",
    "    changes = list(difflib.ndiff(p1,p2))\n",
    "    vowel_set=set(['a','e','i','o','u'])\n",
    "    deleted_vowels=[]\n",
    "    added_vowels=[]\n",
    "    for c in changes:\n",
    "        if '-' in c and c.split(' ')[1] in vowel_set:\n",
    "            deleted_vowels.append(c.split(' ')[1])\n",
    "        elif '+' in c and c.split(' ')[1]:\n",
    "            added_vowels.append(c.split(' ')[1])\n",
    "    if (len(added_vowels)==1) and len(deleted_vowels)==len(added_vowels):\n",
    "        return True, deleted_vowels[0], added_vowels[0]\n",
    "    else:\n",
    "        return False,None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_added_vowel(p1, p2):\n",
    "    changes = list(difflib.ndiff(p1,p2))\n",
    "    vowel_set=set(['a','e','i','o','u'])\n",
    "    deleted_vowels=[]\n",
    "    added_vowels=[]\n",
    "    for c in changes:\n",
    "        if '-' in c:\n",
    "            return False, None,None\n",
    "        elif '+' in c and c.split(' ')[1] in vowel_set:\n",
    "            added_vowels.append(c.split(' ')[1])\n",
    "    if (len(added_vowels)==1):\n",
    "        return True, added_vowels[0], p1[0]\n",
    "    else:\n",
    "        return False,None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_added_consonant(p1, p2):\n",
    "    changes = list(difflib.ndiff(p1,p2))\n",
    "    vowel_set=set(['a','e','i','o','u'])\n",
    "    added_cons=[]\n",
    "    for c in changes:\n",
    "        if '-' in c:\n",
    "            return False, None, None\n",
    "        elif '+' in c and c.split(' ')[1] not in vowel_set:\n",
    "            added_cons.append(c.split(' ')[1])\n",
    "    if (len(added_cons)==1):\n",
    "        return True, added_cons[0], p1[0]\n",
    "    else:\n",
    "        return False,None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/matiello_data.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redups=df[df.label==3].word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redups_tokens=[]\n",
    "for r in redups:\n",
    "    tokens=r.strip().split('-')\n",
    "    if len(tokens) == 2:\n",
    "        redups_tokens.append((tokens[0].lower(), tokens[1].lower()))\n",
    "    else:\n",
    "        tokens=r.strip().split(' ')\n",
    "        if len(tokens) == 2:\n",
    "            redups_tokens.append((tokens[0].lower(), tokens[1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redups_tokens_train, redups_tokens_test = train_test_split(redups_tokens, test_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('./data/redups_train_prob_model.txt','w')\n",
    "for l in redups_tokens_train:\n",
    "    f.write(u' '.join(l)+u'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('./data/redups_test_prob_model.txt','w')\n",
    "for l in redups_tokens_test:\n",
    "    f.write(u' '.join(l)+u'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_model(redups_tokens):\n",
    "    c=Pmf()\n",
    "    vowel_counter=Counter()\n",
    "    consonant_counter=Counter()\n",
    "    added_vowel_counter=Counter()\n",
    "    added_consonant_counter=Counter()\n",
    "\n",
    "    vowel_counter_tot=Pmf()\n",
    "    consonant_counter_tot=Pmf()\n",
    "    added_vowel_counter_tot=Pmf()\n",
    "    added_consonant_counter_tot=Pmf()\n",
    "\n",
    "    for redup in redups_tokens:\n",
    "        if redup[0]==redup[1]:\n",
    "            c['DUPLICATE']+=1\n",
    "        elif is_added_vowel(redup[0], redup[1])[0]:\n",
    "            c['AV']+=1\n",
    "            _,av, fl=is_added_vowel(redup[0], redup[1])\n",
    "            if fl not in added_vowel_counter:\n",
    "                added_vowel_counter[fl]=Pmf()\n",
    "            added_vowel_counter[fl][av]+=1\n",
    "            added_vowel_counter_tot[av]+=1\n",
    "        elif is_added_consonant(redup[0], redup[1])[0]:\n",
    "            #print redup[0], redup[1]\n",
    "            c['AC']+=1\n",
    "            _,ac, fl = is_added_consonant(redup[0], redup[1])\n",
    "            if fl not in added_consonant_counter:\n",
    "                added_consonant_counter[fl]=Pmf()\n",
    "            added_consonant_counter[fl][ac]+=1\n",
    "            added_consonant_counter_tot[ac]+=1\n",
    "        elif is_change_vowel(redup[0], redup[1])[0]:\n",
    "            c['VOWEL']+=1\n",
    "            _, dv, av = is_change_vowel(redup[0], redup[1])\n",
    "            if dv not in vowel_counter:\n",
    "                vowel_counter[dv]=Pmf()\n",
    "            vowel_counter[dv][av]+=1\n",
    "            vowel_counter_tot[dv]+=1\n",
    "        elif is_change_consonant(redup[0], redup[1])[0]:\n",
    "            c['CONSONANT']+=1\n",
    "            _, dv, av = is_change_consonant(redup[0], redup[1])\n",
    "            if dv not in consonant_counter:\n",
    "                consonant_counter[dv]=Pmf()\n",
    "            consonant_counter[dv][av]+=1\n",
    "            consonant_counter_tot[dv]+=1\n",
    "        elif is_shm(redup[0], redup[1]):\n",
    "            c['SHM']+=1\n",
    "        else:\n",
    "            #print \"Unknown\", redup\n",
    "            c['UNKNOWN']+=1\n",
    "\n",
    "    c.normalize()\n",
    "\n",
    "    for d in vowel_counter.values():\n",
    "        d.normalize()\n",
    "\n",
    "    for d in consonant_counter.values():\n",
    "        d.normalize()\n",
    "\n",
    "    vowel_counter_tot.normalize()\n",
    "    consonant_counter_tot.normalize()\n",
    "\n",
    "    for d in added_consonant_counter.values():\n",
    "        d.normalize()\n",
    "\n",
    "    added_consonant_counter_tot.normalize()\n",
    "    return c, consonant_counter, consonant_counter_tot, vowel_counter,\\\n",
    "    vowel_counter_tot, added_vowel_counter, added_vowel_counter_tot, added_consonant_counter, added_consonant_counter_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, consonant_counter, consonant_counter_tot, vowel_counter,vowel_counter_tot,\\\n",
    "added_vowel_counter, added_vowel_counter_tot, added_consonant_counter, added_consonant_counter_tot=learn_model(redups_tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_add_ac(s,added_consonant_counter):\n",
    "    if s[0] in added_consonant_counter:\n",
    "        ac=added_consonant_counter[s[0]].sample()\n",
    "        return ac+s\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_replace(s, total_counter, bicounter):\n",
    "    pos=-1\n",
    "    for i, ch in enumerate(list(s)):\n",
    "        if ch in set(total_counter.keys()):\n",
    "            pos=i\n",
    "            break\n",
    "    ch_target=bicounter[ch].sample()\n",
    "    ret_str=list(s)\n",
    "    ret_str[pos]=ch_target\n",
    "    return ''.join(ret_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def can_replace_vowels(s):\n",
    "    return len(set(list(s)) & set(vowel_counter_tot.keys())) >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def can_replace_consonants(s):\n",
    "    return len(set(list(s)) & set(consonant_counter_tot.keys()))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_reduplicative(s, c):\n",
    "    newc=Pmf()\n",
    "    newc['DUPLICATE']=c['DUPLICATE']\n",
    "    if can_replace_vowels(s):\n",
    "        newc['VOWEL']=c['VOWEL']\n",
    "    if can_replace_consonants(s):\n",
    "        newc['CONSONANT']=c['CONSONANT']\n",
    "    if s[0] in added_consonant_counter:\n",
    "        newc['AC']=c['AC']\n",
    "    newc.normalize()\n",
    "    l1 = newc.sample()\n",
    "    if l1 == 'DUPLICATE':\n",
    "        return s\n",
    "    elif l1 == 'AC':\n",
    "        return generate_add_ac(s, added_consonant_counter)\n",
    "    elif l1 == 'VOWEL':\n",
    "        return generate_replace(s, vowel_counter_tot, vowel_counter)\n",
    "    elif l1 == 'CONSONANT':\n",
    "        return generate_replace(s, consonant_counter_tot, consonant_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_gen_redup(s):\n",
    "    pos=np.random.choice(len(s))\n",
    "    if s[pos] in set(['a','e','i','o','u']):\n",
    "        candidates=set(['a','e','i','o','u'])-set(s[pos])\n",
    "        ch = np.random.choice(list(candidates))\n",
    "        t=list(s)\n",
    "        t[pos]=ch\n",
    "        return ''.join(t)\n",
    "    else:\n",
    "        consonants=set(['b','c','d','f','g','h','j','k','l','m','n','p','q','r','s','t','v','w','x','y','z'])\n",
    "        assert(len(consonants)==21)\n",
    "        candidates=consonants-set(s[pos])\n",
    "        ch = np.random.choice(list(candidates))\n",
    "        t=list(s)\n",
    "        t[pos]=ch\n",
    "        return ''.join(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'flop'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_reduplicative('flip', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_on_test_data(test_data_file, output_directory):\n",
    "    for run in np.arange(0,10):\n",
    "        g = open('{}/redups_prob_model_{}.txt'.format(output_directory, run),'w')\n",
    "        f = open(test_data_file)\n",
    "        for line in f:\n",
    "            redup_tokens = line.strip().split(' ')\n",
    "            generated_token = generate_reduplicative(redup_tokens[0], c)\n",
    "            g.write(u' '.join([redup_tokens[0], generated_token]))\n",
    "            g.write(u'\\n')\n",
    "        g.close()  \n",
    "        \n",
    "    for run in np.arange(0,10):\n",
    "        nodupc=c.copy()\n",
    "        nodupc['DUPLICATE']=0.0\n",
    "        g = open('{}/redups_prob_nodups_model_{}.txt'.format(output_directory, run),'w')\n",
    "        f=open(test_data_file)\n",
    "        for line in f:\n",
    "            redup_tokens = line.strip().split(' ')\n",
    "            generated_token = generate_reduplicative(redup_tokens[0], nodupc)\n",
    "            g.write(u' '.join([redup_tokens[0], generated_token]))\n",
    "            g.write(u'\\n')\n",
    "        g.close()    \n",
    "\n",
    "    for run in np.arange(0,10):\n",
    "        g = open('{}/redups_prob_random_model_{}.txt'.format(output_directory, run),'w')\n",
    "        f=open(test_data_file)\n",
    "        for line in f:\n",
    "            redup_tokens = line.strip().split(' ')\n",
    "            generated_token = random_gen_redup(redup_tokens[0])\n",
    "            g.write(u' '.join([redup_tokens[0], generated_token]))\n",
    "            g.write(u'\\n')\n",
    "        g.close()    \n",
    "\n",
    "    for run in np.arange(0,10):\n",
    "        g = open('{}/redups_prob_random_char_model_{}.txt'.format(output_directory, run),'w')\n",
    "        f=open(test_data_file)\n",
    "        for line in f:\n",
    "            redup_tokens = line.strip().split(' ')\n",
    "            generated_token = random_gen_char(redup_tokens[0])\n",
    "            g.write(u' '.join([redup_tokens[0], generated_token]))\n",
    "            g.write(u'\\n')\n",
    "        g.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate_on_test_data('./data/redups_test_prob_model.txt', './output/gold_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate_on_test_data('./data/redups_test_ud.txt', './output/test_ud/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
